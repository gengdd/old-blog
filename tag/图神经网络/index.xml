<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>图神经网络 | GDD</title>
    <link>https://gengdd.github.io/tag/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</link>
      <atom:link href="https://gengdd.github.io/tag/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/index.xml" rel="self" type="application/rss+xml" />
    <description>图神经网络</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>zh</language><lastBuildDate>Fri, 06 Aug 2021 22:00:16 +0800</lastBuildDate>
    <image>
      <url>https://gengdd.github.io/media/icon_hu4b9c718166280bb42d9325f20dee7c58_11030_512x512_fill_lanczos_center_2.png</url>
      <title>图神经网络</title>
      <link>https://gengdd.github.io/tag/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</link>
    </image>
    
    <item>
      <title>基于骨架数据的时空Inception图卷积动作识别</title>
      <link>https://gengdd.github.io/post/%E5%9F%BA%E4%BA%8E%E9%AA%A8%E6%9E%B6%E6%95%B0%E6%8D%AE%E7%9A%84%E6%97%B6%E7%A9%BAinception%E5%9B%BE%E5%8D%B7%E7%A7%AF%E5%8A%A8%E4%BD%9C%E8%AF%86%E5%88%AB/</link>
      <pubDate>Fri, 06 Aug 2021 22:00:16 +0800</pubDate>
      <guid>https://gengdd.github.io/post/%E5%9F%BA%E4%BA%8E%E9%AA%A8%E6%9E%B6%E6%95%B0%E6%8D%AE%E7%9A%84%E6%97%B6%E7%A9%BAinception%E5%9B%BE%E5%8D%B7%E7%A7%AF%E5%8A%A8%E4%BD%9C%E8%AF%86%E5%88%AB/</guid>
      <description>&lt;center&gt;&lt;div style=&#34;font-size:20pt&#34;&gt;Spatio-Temporal Inception Graph Convolutional Networks for Skeleton-Based Action Recognition&lt;/div&gt;&lt;/center&gt;
&lt;div&gt;
&lt;div style=&#34;width:60px;float:left; font-family:方正公文黑体;&#34;&gt;摘要:&lt;/div&gt; 
&lt;div style=&#34;overflow:hidden; font-family:华文楷体;&#34;&gt;随着深度传感器的普及，基于骨架的人体动作识别引起了广泛关注。最近，图卷积网络(GCN)由于其强大的图形数据建模能力而被广泛用于这项任务。邻接图的拓扑结构是建模输入骨架相关性的关键因素。因此，以前的方法主要关注于图拓扑的设计/学习。但一旦拓扑结构被学习，网络的每一层中只存在一个单一的尺度特征和一个变换。许多在卷积神经网络(CNN)中被证明非常有效的见解，如多尺度信息和多组变换，尚未在GCN中进行研究。原因是由于图形结构的骨架数据与传统的图像/视频数据之间的差距，将这些见解嵌入GCN非常具有挑战性。为了克服这一差距，我们在GCNs中重新设计了用于骨架序列处理的split-transform-merge策略。具体来说，我们设计了一个简单且高度模块化的图形卷积网络架构，用于基于骨架的动作识别。我们的网络是通过重复一个模型块来构建的，该模型块聚集了来自空间和时间路径的多粒度信息。大量的实验表明，我们的网络性能优于最先进的方法，只需1/5的参数和1/10的FLOPs，就有显著的优势。&lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;introduction&#34;&gt;INTRODUCTION&lt;/h2&gt;
&lt;p&gt;人类行为识别因其潜在的应用前景而受到广泛关注。近年来，基于骨架的动作识别得到了广泛的研究，因为骨架数据传递了人体运动的紧凑信息，并且对动态环境（如视点变化、遮挡和复杂背景）具有很强的适应性。由于骨架数据自然位于非欧几里德空间，关节作为顶点，它们在人体内的连接作为边缘，因此基于CNN和RNN的方法无法充分利用骨架数据的图形结构中传递的丰富信息。&lt;/p&gt;
&lt;p&gt;最近，图卷积网络以其处理图形数据的优越能力被引入基于骨架的动作识别，并取得了最先进的性能。这些方法大多侧重于图拓扑的设计/学习。那些基于GCN的backbone在从不同尺度提取和合成信息以及从不同层次的不同路径进行转换方面存在固有的局限性。&lt;/p&gt;
&lt;p&gt;直观地说，CNN设计理念中的许多见解可以集成到基于GCN的主干网络中。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;输入可以通过一些低维嵌入或标识映射（GoogLeNet、ResNeXt、ResNet）分成不同的路径&lt;/li&gt;
&lt;li&gt;每个路径可以应用不同的transformations（GoogLeNet，ResNeXt）&lt;/li&gt;
&lt;li&gt;所有路径的输出都可以通过串联或求和进行聚合（ResNet、ResNeXt、GoogLeNet、DenseNet）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;然而，由于骨架数据的图结构，将这些理念嵌入GCN非常具有挑战性。例如，对于多尺度空间处理，不需要在CNN中使用多个内核大小，GCN需要针对不同阶跃点连接的定制操作。对于多视图时间处理（位置和运动），仍然不涉及为骨架序列图卷积的运动特征。事实上，许多生物学研究表明，灵长类视觉系统中20%的细胞对动态运动变化有反应，但对空间细节不敏感。&lt;/p&gt;
&lt;p&gt;在本文中，我们采用了CNN中的重复层策略，并重新设计了GCN中的分割-变换-合并策略，用于每一层的空间和时间骨架序列处理。对于每一层，输入分为三条路径：空间路径用于空间特征，时间路径用于序列特征和残差连接用于从用输入特征。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/008i3skNly1gt0geyk4s6j30ff07mmxd.jpg&#34; alt=&#34;image-20210731212911027&#34; style=&#34;zoom:80%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/008i3skNly1gt0gf2u0gzj30ig09q74y.jpg&#34; alt=&#34;image-20210731212925742&#34; style=&#34;zoom:80%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;空间路径（空间Inception）进一步分为四个分支。我们使用1-4阶邻接采样作为带1-4跳连接的图变换集。然后使用1×1卷积、批归一化和ReLU的特定图形变换。时间路径（时间Inception）由两组变换组成。一组是连续帧中相同关节位置特征的直接图卷积，另一组是连续帧中相同关节运动特征的图卷积。值得注意的是，这是首次将关节的运动特征用于基于骨架的动作识别。最后，在合并阶段，首先对空间路径和时间路径的输出进行级联，并使用1×1卷积进行融合。然后，三条路径的特征通过求和进行聚合。整个块因其与CNN中的Inception模块相似而被命名为时空Inception模块。&lt;/p&gt;
&lt;p&gt;为了验证我们提出的时空Inception图卷积网络（STIGCN）用于基于骨架的动作识别的优越性，在两个大规模数据集上进行了大量实验。我们的网络比最先进的方法有很大的优势，只有1/5的参数和1/10的FLOPs。此外，虽然其他方法依赖于双流管道，需要骨架数据和精心制作的骨骼数据作为输入，但我们的方法只需要原始骨架数据作为输入。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;我们提出了一种用于基于骨架的动作识别的图卷积主干结构，称为时空Inception图卷积网络。该网络克服了方法在从不同层次的不同路径提取和合成不同规模和转换信息方面的局限性&lt;/li&gt;
&lt;li&gt;为了克服CNN和GCN之间卷积运算的差距，我们在GCN中重新设计了用于骨架序列处理的分割变换合并策略&lt;/li&gt;
&lt;li&gt;我们的方法表明增加变换集的数量比简单地创建更宽的GCN更有效地获得精度。我们希望这一见解将有助于时空序列分析中基于GCN的主干的迭代&lt;/li&gt;
&lt;li&gt;在两个用于基于骨架的动作识别的大规模数据集上，所提出的网络比最先进的方法具有显著的优势，参数和FLOPs更少。将发布代码和预训练模型，以促进未来的相关研究。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;related-work&#34;&gt;RELATED WORK&lt;/h2&gt;
&lt;h3 id=&#34;skeleton-based-action-recognition&#34;&gt;Skeleton-Based Action Recognition&lt;/h3&gt;
&lt;p&gt;最近，GCNs被引入到基于骨架的动作识别中，并取得了最先进的性能。这些方法大多侧重于图拓扑的设计/学习。Yan等人首先引入GCNs对骨架数据进行建模，并构建了具有固定拓扑约束的预定义图。Shi等人提出通过参数化图来学习自适应图，然后使用卷积参数联合更新图。Gao等人引入了图的更大感受野的高阶近似，并通过解决稀疏回归问题来学习它。Peng等人试图通过NAS搜索不同层的不同图形。&lt;/p&gt;
&lt;h3 id=&#34;backbone-convolutional-neural-networks&#34;&gt;Backbone Convolutional Neural Networks&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;GoogLeNet&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/008i3skNly1gt0h7zh4lij30lz0bjmxy.jpg&#34; alt=&#34;image-20210731215800024&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ResNet&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/008i3skNly1gt0h9b1csfj30hc06bt8u.jpg&#34; alt=&#34;image-20210731215915147&#34; style=&#34;zoom:70%;&#34; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;DenseNet&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/008i3skNly1gt0k0envikj30d709vwf7.jpg&#34; alt=&#34;image-20210731233427289&#34; style=&#34;zoom:67%;&#34; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ResNeXT&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/008i3skNly1gt0ijv96ruj30bs070q3f.jpg&#34; alt=&#34;image-20210731224358000&#34; style=&#34;zoom:70%;&#34; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;LocalCNN&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;graph-convolutional-networks&#34;&gt;Graph Convolutional Networks&lt;/h3&gt;
&lt;p&gt;GCN广泛用于不规则数据，例如社交网络和生物数据。关键的挑战是定义图上的卷积，这很困难，因为图数据是无序的。GCN的构建主要空间视角或谱域视角。空间方法直接对图形顶点及其邻域执行卷积，然后根据手动设计的规则对输出进行规格化。谱域GCN通过图拉普拉斯方法将图形信号转换到谱域，然后在谱域上应用滤波器。&lt;/p&gt;
&lt;h2 id=&#34;approach&#34;&gt;APPROACH&lt;/h2&gt;
&lt;h3 id=&#34;motivation&#34;&gt;Motivation&lt;/h3&gt;
&lt;p&gt;现有方法的主干网络在从不同层次的不同路径提取和合成不同尺度和变换信息方面具有内在的局限性。&lt;/p&gt;
&lt;h3 id=&#34;instantiation&#34;&gt;Instantiation&lt;/h3&gt;
&lt;p&gt;定义无向图$\mathcal{G}={\mathcal{V},\mathcal{E},A}$&lt;/p&gt;
&lt;p&gt;切比雪夫图卷积定义如下：
$$
F_{\text {out }}=\sum_{r=0}^{R} \theta_{r}^{\prime} T_{r}(\hat{L}) F_{\text {in }},
$$&lt;/p&gt;
&lt;p&gt;$$
T_{r}(\hat{L})=2 \hat{L} T_{r-1}(\hat{L})-T_{r-2}(\hat{L}^{\prime})
$$&lt;/p&gt;
&lt;h4 id=&#34;spatial-inception&#34;&gt;Spatial Inception&lt;/h4&gt;
&lt;p&gt;每个Inception路径有三个部分：采样、卷积和融合。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Adjacency Sampling&lt;/p&gt;
&lt;p&gt;受图卷积的谱公式的启发，我们将特征采样模块重新表示为骨架表示和定义为切比雪夫多项式的图变换之间的矩阵乘法运算。
$$
T_{0}=I
$$&lt;/p&gt;
&lt;p&gt;$$
T_{1}=\hat{L}
$$&lt;/p&gt;
&lt;p&gt;$$
T_{2}=2 \hat{L}^{2}-I
$$&lt;/p&gt;
&lt;p&gt;$$
T_{3}=4 \hat{L}^{3}-3 \hat{L}
$$&lt;/p&gt;
&lt;p&gt;$$
T_{4}=8 \hat{L}^{4}-8 \hat{L}^{2}+I
$$&lt;/p&gt;
&lt;p&gt;借鉴自适应图拓扑方法，我们将层相关偏差和数据相关偏差应用于转换矩阵，以实现更灵活的跳连接。除自适应偏差外，预定义变换矩阵的其他参数在训练期间是固定的。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Convolution Module&lt;/p&gt;
&lt;p&gt;图卷积模块用于提取各个尺度的图特征。它由1×1卷积层、批量归一化层和ReLU层组成。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Fusion Module&lt;/p&gt;
&lt;p&gt;引入特征融合模块，通过综合所有路径的输出，生成更具鲁棒性和区分性的表示。在本文中，特征融合模块形成为所有输出的级联层，然后是具有批量归一化和ReLU的1×1卷积层。将1×1卷积层的输出通道数设置为输入通道数，以保持基数。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;temporal-inception&#34;&gt;Temporal Inception&lt;/h4&gt;
&lt;p&gt;一个分支直接将连续帧中相同关节的特征作为位置特征处理的输入。另一个分支将输入到运动采样模块以进行运动特征处理。这是首次将关节的运动特征用于基于骨架的动作识别。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Motion Sampling&lt;/p&gt;
&lt;p&gt;在本文中，我们设计了一个运动采样模块来显式地建模二阶时间信息，称为运动信息。特别地，运动信息被定义为连续帧之间的差。&lt;/p&gt;
&lt;p&gt;运动信息也可以看作是骨架序列的光流。骨架数据的关节类似于RGB视频中观察到的对象，光流计算为连续帧之间对象的相对运动。因此，利用上述运动采样操作进行运动特征处理是自然的。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Convolution and Fusion&lt;/p&gt;
&lt;p&gt;我们使用3×1核进行时间卷积，其中核大小3对应于时间跨度，在输入序列中的相邻特征映射上构造时间连接。特征融合模块将两个时间分支的输出连接起来，然后进行1×1卷积、批量归一化和ReLU。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;spatio-temporal-fusion&#34;&gt;Spatio-Temporal Fusion&lt;/h4&gt;
&lt;p&gt;在最后的合并阶段，空间路径、时间路径和残差路径的输出通过求和进行聚合。&lt;/p&gt;
&lt;h3 id=&#34;network-architecture&#34;&gt;Network Architecture&lt;/h3&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/008i3skNly1gt0iwuoxcej30lo04rmxt.jpg&#34; alt=&#34;image-20210731225634147&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/008i3skNly1gt0izi345jj30ap0c975c.jpg&#34; alt=&#34;image-20210731225900841&#34; style=&#34;zoom:90%;&#34; /&gt;&lt;/p&gt;
&lt;h2 id=&#34;experiments&#34;&gt;EXPERIMENTS&lt;/h2&gt;
&lt;h3 id=&#34;datasets-and-evaluation-protocol&#34;&gt;Datasets and Evaluation Protocol&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;NTU RGB+D&lt;/li&gt;
&lt;li&gt;Kinetics-Skeleton&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;implementation-details&#34;&gt;Implementation Details&lt;/h3&gt;
&lt;p&gt;我们的框架是在PyTorch上实现的。所有实验都使用Nesterov动量为0.9的随机梯度下降。对于NTU RGB+D，批量大小为64，权重衰减为5e−4，初始学习率为0.1。在第30和40个Epoch，学习率除以10。训练过程在第50个Epoch结束。对于KineticsSkeleton，批量大小为128，Epoch为60。学习率在开始时设置为0.1，在第45和第50个时期除以10，权重衰减为1.5e−4。&lt;/p&gt;
&lt;h3 id=&#34;comparison-with-state-of-the-art-methods&#34;&gt;Comparison with State-of-the-Art Methods&lt;/h3&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/008i3skNly1gt0j7mcj9hj30at0bxgme.jpg&#34; alt=&#34;image-20210731230654325&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/008i3skNly1gt0j81r3xvj30az06rdg6.jpg&#34; alt=&#34;image-20210731230719875&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;ablation-analysis&#34;&gt;Ablation Analysis&lt;/h3&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/008i3skNly1gt0j9x4jz6j30lr05eaah.jpg&#34; alt=&#34;image-20210731230908425&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;CONCLUSION&lt;/h2&gt;
&lt;p&gt;在本文中，我们提出了一种简单的图卷积主干结构，称为时空Inception图卷积网络，用于基于骨架的动作识别。它克服了以往方法从不同层次的不同路径中提取和合成不同尺度和变换信息的局限性。在两个大规模数据集上，所提出的网络比最先进的方法有显著的优势，参数和FLOPs更少。我们的方法表明，增加变换集的数量比简单地创建更宽的GCN更有效地获得精度。我们希望这一见解将有助于基于GCN的主干网在时空序列分析中的迭代。在未来，我们将探索更多类型的转换来设计图卷积构建块。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>细粒度城市流量预测</title>
      <link>https://gengdd.github.io/post/%E7%BB%86%E7%B2%92%E5%BA%A6%E5%9F%8E%E5%B8%82%E6%B5%81%E9%87%8F%E9%A2%84%E6%B5%8B/</link>
      <pubDate>Fri, 23 Jul 2021 23:02:53 +0800</pubDate>
      <guid>https://gengdd.github.io/post/%E7%BB%86%E7%B2%92%E5%BA%A6%E5%9F%8E%E5%B8%82%E6%B5%81%E9%87%8F%E9%A2%84%E6%B5%8B/</guid>
      <description>&lt;center&gt;&lt;div style=&#34;font-family:华文楷体;font-size:30pt&#34;&gt;细粒度城市流量预测&lt;/div&gt;&lt;/center&gt;
&lt;div&gt;
&lt;div style=&#34;width:60px;float:left; font-family:方正公文黑体;&#34;&gt;摘要:&lt;/div&gt; 
&lt;div style=&#34;overflow:hidden; font-family:华文楷体;&#34;&gt;城市流量预测对智慧城市在交通管理和风险评估等方面有很大的帮助。我们将城市流量预测由粗粒度扩展到细粒度，提出了以下具体的挑战：(1)细粒度数据中观测网格间的转移至关重要，这使得在全域范围内捕获网格单元之间的空间依赖性变得更加复杂(2)在大量独立网格单元中学习外部因素的影响具有挑战。我们提出了一个时空关系网络(Spatio-Temporal Relation Network，STRN)来预测细粒度的城市流量。首先，使用骨干网络来学习每个单元格的高层次表示。其次，我们提出了一个全局关系模块(Global Relation Module，GloNet)，与现有方法相比，该模块可以更有效地捕获全局空间依赖关系。第三，我们设计了一个元学习器，将外部因素和土地功能(如POI密度)作为输入以处理元知识并提高模型性能。&lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;introduction&#34;&gt;INTRODUCTION&lt;/h2&gt;
&lt;p&gt;在基于网格的城市流量预测中，必须考虑的一个关键属性是时空(ST)相关性：网格单元的未来状态取决于自身和邻居的历史状态。此外，城市流量也受到天气条件和事件等外部因素的影响。例如，大雪可以大大减少许多地区的交通流量。许多现有的研究使用卷积神经网络(CNNs)作为骨干结构来提取空间上的近距离依赖关系；时间依赖关系(例如，最近的、每天的和每周的级别)是使用不同的子分支来捕获的。同时，通过一些人工设计的子网对外部因素的影响进行编码。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/008i3skNly1gsf4yn598oj30lu0a046e.jpg&#34; alt=&#34;image-20210713105637603&#34; style=&#34;zoom:45%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;对于特定的城市，增加粒度(例如:600m→150m)相当于获得更高的分辨率(如32×32→128×128)。因此，我们可以交替使用“高分辨率”和“细粒度”。尽管之前的研究在粗粒度级别(如32×32)上取得了很好的结果，但由于以下具体挑战，他们的架构并不适合预测细粒度的城市流量:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;全局空间依赖性
&lt;ol&gt;
&lt;li&gt;CNN多层堆叠&lt;/li&gt;
&lt;li&gt;膨胀卷积&lt;/li&gt;
&lt;li&gt;DeepSTN+：显式建模所有成对关系网格网格，引入大量参数&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;外部因素与土地功能
&lt;ol&gt;
&lt;li&gt;之前的研究如DeepST和ST-ResNet使用子网将外部因素的影响映射到每个网格单元上，这种方法扩展到细粒度将增大大量参数&lt;/li&gt;
&lt;li&gt;使用外部因素只学习不同类型POI特征的权重，而忽略了外部因素对不同网格单元的影响存在显著差异&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;我们提出了一个用于细粒度城市流预测的时空关系网络(STRN)，STRN遵循CPT范式对三种时间依赖进行建模，并使用基于CNN的主干来提取高层ST特征。为了解决上述挑战，我们设计了如下两个具体模块：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;引入一个新的结构(GloNet)来捕获全局空间依赖性
&lt;ol&gt;
&lt;li&gt;在更高级的语义层(即区域层)上执行关系推断，该语义层对捕获全局关系更友好&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;提出了一种基于矩阵分解的元学习器来应用随时变化的外部因素响应&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/008i3skNly1gsf7r9kwqzj30n40c076o.jpg&#34; alt=&#34;image-20210713123338325&#34; style=&#34;zoom:40%;&#34; /&gt;&lt;/p&gt;
&lt;h2 id=&#34;formulation&#34;&gt;FORMULATION&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;网格单元$N=H\times W$&lt;/p&gt;
&lt;p&gt;将感兴趣的区域（例如一个城市地区）均匀地划分为一个$H\times W$栅格，栅格中共有$HW$个网格单元&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;城市流量$X_t \in \mathbb{R}^{K\times H \times W}$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;区域(Region)$B\in \mathbb{R}^{N\times M}$&lt;/p&gt;
&lt;p&gt;土地使用和功能赋予不规则区域以不同的地理语义。与基于网格的方法相比，它为我们提供了更自然和语义上的城市空间分割。$B\in \mathbb{R}^{N\times M}$表示分配规则，其中每个元素$b_{ij}$代表是网格单元$i$属于区域$j$的可能性，而M是区域数量&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;外部因素(天气)$e_t \in \mathbb{R}^{l_e}$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;土地特征$P\in \mathbb{R}^{l_f\times H\times W}$&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/008i3skNly1gsf84jc082j60mm0a244n02.jpg&#34; alt=&#34;image-20210713124622097&#34; style=&#34;zoom:40%;&#34; /&gt;&lt;/p&gt;
&lt;h2 id=&#34;methodology&#34;&gt;METHODOLOGY&lt;/h2&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/008i3skNly1gsf9qn9ga0j319c0dy11g.jpg&#34; alt=&#34;image-20210713134220630&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/008i3skNly1gsfcs95lkrj30mq072q3v.jpg&#34; alt=&#34;image-20210713152655526&#34; style=&#34;zoom:40%;&#34; /&gt;&lt;/p&gt;
&lt;h3 id=&#34;backbone-network&#34;&gt;Backbone Network&lt;/h3&gt;
&lt;p&gt;我们采用了SENet(Squeeze-and-Excitation Network, SENet)来融合每一层小的(即局部的)接受域内的空间和通道信息，该方法已经被证明能够有效地产生每个网格单元的特征。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/008i3skNly1gsfa2gr3hbj30mk0gk40k.jpg&#34; alt=&#34;image-20210713135335131&#34; style=&#34;zoom:40%;&#34; /&gt;
$$
z_c=F_{sq}(u_c)=\frac{1}{W\times H}\sum _{i=1}^{W}\sum _{j=1}^Hu_c(i,j)
$$&lt;/p&gt;
&lt;p&gt;$$
s=F_{ex}(z,W)=\sigma (W_2\delta(W_1z))
$$&lt;/p&gt;
&lt;p&gt;$$
\tilde{x_{c}}=F_{scale}(u_c, s_c)=s_c \cdot u_c
$$&lt;/p&gt;
&lt;h3 id=&#34;global-relation-module&#34;&gt;Global Relation Module&lt;/h3&gt;
&lt;p&gt;提取完网格单元的局部特征后，本文提出了一个全局关系模块，相比现有方法能更高效地捕获全局空间关系。受图像关系推理网络的启发，提出在更高的语义级别（即区域级别）执行关系推理。该语义级别更易于捕获全局关系。此外，基于最小割（Minimum Cut）理论为区域划分设计了无监督损失。&lt;/p&gt;
&lt;p&gt;全局关系网络的整个流程包括四个主要阶段：区域划分，空间转换，消息传递（关系推断），反空间转换和预测。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/008i3skNly1gsfacvq55rj319a0a00vf.jpg&#34; alt=&#34;image-20210713140344902&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h4 id=&#34;region-partition&#34;&gt;Region Partition&lt;/h4&gt;
&lt;p&gt;简单通过线性变换不能保证相邻网格单元在分割当中的临近性。为此，使用最小割理论去约束分配矩阵的生成。
$$
B=\text{softmax}(\delta(X^h)), X^h\in \mathbb{R}^{N\times C}\quad B\in \mathbb{R}^{N\times M}
$$&lt;/p&gt;
&lt;p&gt;$$
\mathcal{L}_c = -\frac{\text{Tr}(\mathbf{B}^T\tilde{\mathbf{A}}^g\mathbf{B})}{\text{Tr}(\mathbf{B}^T\tilde{\mathbf{D}}^g\mathbf{B})}
$$&lt;/p&gt;
&lt;p&gt;$$
a = \frac{\mathbf{B}^{T} \mathbf{B}}{\left|\mathbf{B}^{T} \mathbf{B}\right|_{F}}
$$&lt;/p&gt;
&lt;p&gt;$$
b = \frac{\mathbf{I}_{M}}{\sqrt{M}}
$$&lt;/p&gt;
&lt;p&gt;$$
\mathcal{L}_m = -\mathcal{L}_c+||a-b||_F
$$&lt;/p&gt;
&lt;p&gt;$\mathbf{\hat{B}}$ assigns exactly $N/M$ grid cells to each region&lt;/p&gt;
&lt;h4 id=&#34;space-conversion&#34;&gt;Space Conversion&lt;/h4&gt;
&lt;p&gt;根据分配矩阵B，将局部网格单元特征聚合到区域空间中以获得区域特征，并生成区域间的连接关系（即区域网络的邻接矩阵）。
$$
H = B^T\phi(X^h), A^r = B^T\tilde{A}^gB, A\in\mathbb{R}^{N\times N}
$$&lt;/p&gt;
&lt;h4 id=&#34;message-passing-between-regions&#34;&gt;Message Passing between Regions&lt;/h4&gt;
&lt;p&gt;由于区域以图的形式连接，因此利用图卷积网络在区域级别执行消息传递，来进行全局关系的建模。
$$
\hat{A}^r = A_r - \text{diag}(A^r),\tilde{A}^r = \hat{D}^{-\frac{1}{2}}\hat{A}^r\hat{D}^{-\frac{1}{2}}
$$&lt;/p&gt;
&lt;p&gt;$$
H^{&#39;}=f_{\text{GCN}}(\tilde{A}^r,H)=\tilde{A}^r\text{ReLU}(\tilde{A}^rHW_1)W_2
$$&lt;/p&gt;
&lt;h4 id=&#34;reverse-projection&#34;&gt;Reverse projection&lt;/h4&gt;
&lt;p&gt;当得到全局关系建模后的高阶区域特征后，根据分配矩阵B进行反投影到原网格空间，得到全局关系增强的网格单元特征。最后，把该全局关系增强的网格单元特征输入到预测器进行预测。
$$
X^g=B\theta(H^{&#39;}) \in \mathbb{R}^{N\times C}
$$&lt;/p&gt;
&lt;h4 id=&#34;reshape--predict&#34;&gt;Reshape &amp;amp; Predict&lt;/h4&gt;
&lt;p&gt;首先Reshape成$\mathbb{R}^{C\times H\times W}$，然后使用$1\times 1$卷积到$\mathbb{R}^{K\times H\times W}$做残差连接&lt;/p&gt;
&lt;h3 id=&#34;meta-learner&#34;&gt;Meta Learner&lt;/h3&gt;
&lt;p&gt;通常，具有相似地块功能的网格单元将对外部因素具有相似的响应。基于此观察，本文设计了一种新颖的元学习器，以基于矩阵分解对外部因素产生特定于网格单元的影响。给定地块特征和外部特征，目标是计算每一个网格的响应。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/008i3skNly1gsfc0owl23j30no09wgnp.jpg&#34; alt=&#34;image-20210713150103560&#34; style=&#34;zoom:50%;&#34; /&gt;
$$
O^m = f_{\text{ML}}(P, e_t) \in \mathbb{R}^{D\times H\times W}
$$&lt;/p&gt;
&lt;h3 id=&#34;optimization&#34;&gt;Optimization&lt;/h3&gt;
&lt;p&gt;$$
\mathcal{L}=\mathcal{L}_{MAE} + \alpha \mathcal{L}_m
$$&lt;/p&gt;
&lt;h2 id=&#34;evaluation&#34;&gt;EVALUATION&lt;/h2&gt;
&lt;h3 id=&#34;论文使用的数据集&#34;&gt;论文使用的数据集&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://i.loli.net/2021/07/20/YeDo36xUQ5cHvqp.png&#34; alt=&#34;image-20210720100740572&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;h3 id=&#34;实验结果&#34;&gt;实验结果&lt;/h3&gt;
&lt;p&gt;不同方法在Taxi BJ数据集上的实验效果对比：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/008i3skNly1gsfcibndtfj30na0gsn0d.jpg&#34; alt=&#34;image-20210713151801457&#34; style=&#34;zoom:40%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/008i3skNly1gsfclkuj85j319i0ek0xi.jpg&#34; alt=&#34;image-20210713152111431&#34; style=&#34;zoom:80%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;论文在此还实验分析了Backbone Network、GloNet、元学习器的有效性在此不再赘述。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://i.loli.net/2021/07/20/XjbCniMgs69rDpu.png&#34; alt=&#34;image-20210720100851086&#34; style=&#34;zoom: 80%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://i.loli.net/2021/07/20/8thuUoEFTpgy1re.png&#34; alt=&#34;image-20210720100939096&#34; style=&#34;zoom:80%;&#34; /&gt;&lt;/p&gt;
&lt;h2 id=&#34;结论&#34;&gt;结论&lt;/h2&gt;
&lt;p&gt;面向智慧城市建设中精细化管理需求，本文提出一种时空关系网络来解决细粒度城市流量预测问题，对于城市的交通规划、公共安全、社会治理都有着非常重要的作用和意义。针对研究问题的两大挑战，本文方法构建了全局关系网络和一种轻量元学习网络，实现对空间（局部和全局）、时间依赖关系以及外部关系（例如天气和兴趣点）的高效学习，并在两个现实世界的细粒度数据集上进行实验，验证了所提方法的有效性。与现有方法相比，本文所提方法可以提供高分辨率流量预测数据，同时模型参数量不受流量粒度变化影响，避免了参数爆炸问题。因此该方法便于移动部署，拥有广泛的应用价值。考虑到落地应用中的实时监测预警需求，未来研究工作中，我们尝试将其扩展至在线学习框架中，进一步提升其应用价值。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;参考文献&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;[1] Liang Y, Ouyang K, Sun J, et al. Fine-Grained Urban Flow Prediction[C]//Proceedings of the Web Conference 2021. 2021: 1833-1845.&lt;/p&gt;
&lt;p&gt;[2] &lt;a href=&#34;https://blog.csdn.net/zuiyishihefang/article/details/114958537&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;WWW2021论文速递：细粒度城市流量预测&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[3] &lt;a href=&#34;https://zhuanlan.zhihu.com/p/368740161&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;WWW2021：细粒度城市流量预测&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[4] &lt;a href=&#34;https://zhuanlan.zhihu.com/p/65459972&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;﻿最后一届ImageNet冠军模型：SENet&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
